<h1>CS225 Final Project Proposal</h1>

<h2>sdaaram2-ajitps2-eshaan2-tulsian3</h2>

<h2>Leading Question</h2>
<p> We are hoping to develop a program that can route us through the shortest path between two Wikipedia articles given that they are in the dataset. We also want to see whether there are certain "super-articles" that help route tons of articles between one another. We believe our first guiding idea is possible in our given time frame and utilizes what we will learn in class but also challenge us to explore outside out the curriculum for solutions. Our second idea might require more research and learning to figure out and we expect there to be some challenges along to way with run time given the scale of the dataset we have chosen. A successful project for our team would include a CLI interface where a user can enter a source and a target and recieve an output or prompt for the shortest path between two articles in an appropriate amount of time. For the second part, our user should be able to prompt for a list of such "super-articles" </p>

<h2>Dataset Acquisition and Processing</h2>
<p> We plan to use the Wikispeedia data set from the Stanford Large Network Dataset Collection. The data can be found here: https://snap.stanford.edu/data/wikispeedia.html. We plan to store the data on this repository so that everyone has the same copy to the data through their own machine, whether EWS or personal computer. The dataset is in the type .tsv but we plan to convert this into a .csv so that we can easily parse through our dataset delimiting it by the commas and line breaks. We will commit the .csv data into the repository under a directory titled "data". Once we have our data inside our repository, we will be creating a custom file reader class and overloading the ">>" operator to easily read in csv files. We will explore the potential of using a CSV library in C++ if a custom operator does not working. We plan to store our data in a map where the Wikipedia article title is the key, and the value is a vector of all article titles that are linked within an article's page. We expect there to be some errors initially with properly parsing and serializing the .tsv files into .csv files but we plan to use online converters to mitigate as much manual work as possible. </p>

<h2>Graph Algorithms</h2>
<p>In order to find the shortest path, we will plan to implement Dijkstra's Algorithm since it will give us the shortest path between two nodes using a BFS. To determine super-articles, we plan to look into the Betweeness Centrality and utilize the algorithm to rank articles based on number of shortest paths going through those articles. For the shortest path method, it will take in a source and a target, while the method to determine the super-articles will just be a method with no parameters since there is no way to change the ranking of articles with most shortest paths through them. For the shortest path, our time complexity to be Elog(V) and for the betweeness centrality, we expect it to be E^2 * (log(V))^2 since we would need to run through the shortest paths between every pair of nodes.</p>

<h2>Timeline</h2>
<p>We think that we can finish this project in an appropriate timeframe. The first week will be dedicated to properly parsing our data and creating appropriate objects to store our data. By the mid-project checkin, we should have our shortest path functionality complete and ready to get to finding our super articles. We think this will take a longer timeframe since there is a lot we do not know yet. We believe that we have the resources to figure it out by the deadline given that we have a mentor, the internet, and tons of student and faculty at this school that are knowledgable and can direct us to resources that can help us.</p>

